name: 💾 Automated Backup

on:
  schedule:
    - cron: '0 3 * * *' # Daily at 3 AM UTC
  workflow_dispatch:
    inputs:
      backup_type:
        description: 'Type of backup to perform'
        required: true
        default: 'full'
        type: choice
        options:
        - full
        - database
        - media
        - config

env:
  BACKUP_RETENTION_DAYS: 7

jobs:
  backup:
    runs-on: ubuntu-latest
    environment: production

    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4

    - name: 🔐 Setup SSH
      uses: webfactory/ssh-agent@v0.9.0
      with:
        ssh-private-key: ${{ secrets.SERVER_SSH_KEY }}

    - name: 📋 Create backup script
      run: |
        cat > backup.sh << 'EOF'
        #!/bin/bash
        set -e
        
        echo "💾 Starting backup process..."
        
        # Variables
        BACKUP_DIR="/opt/backups"
        TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
        BACKUP_TYPE="${{ github.event.inputs.backup_type || 'full' }}"
        
        # Create backup directory
        mkdir -p ${BACKUP_DIR}/${TIMESTAMP}
        
        cd /opt/ehit_backend
        
        case ${BACKUP_TYPE} in
          "database")
            echo "🗄️ Backing up database..."
            docker-compose -f docker-compose.prod.yml exec -T db pg_dump -U ehit_user ehit_db > ${BACKUP_DIR}/${TIMESTAMP}/database.sql
            ;;
          "media")
            echo "📁 Backing up media files..."
            tar -czf ${BACKUP_DIR}/${TIMESTAMP}/media.tar.gz media/
            ;;
          "config")
            echo "⚙️ Backing up configuration..."
            tar -czf ${BACKUP_DIR}/${TIMESTAMP}/config.tar.gz docker-compose.prod.yml nginx.conf .env
            ;;
          "full"|*)
            echo "🔄 Performing full backup..."
            
            # Database backup
            echo "🗄️ Backing up database..."
            docker-compose -f docker-compose.prod.yml exec -T db pg_dump -U ehit_user ehit_db > ${BACKUP_DIR}/${TIMESTAMP}/database.sql
            
            # Media files backup
            echo "📁 Backing up media files..."
            tar -czf ${BACKUP_DIR}/${TIMESTAMP}/media.tar.gz media/
            
            # Static files backup
            echo "📦 Backing up static files..."
            tar -czf ${BACKUP_DIR}/${TIMESTAMP}/static.tar.gz staticfiles/
            
            # Configuration backup
            echo "⚙️ Backing up configuration..."
            tar -czf ${BACKUP_DIR}/${TIMESTAMP}/config.tar.gz docker-compose.prod.yml nginx.conf .env
            
            # Docker volumes backup
            echo "🐳 Backing up Docker volumes..."
            docker run --rm -v ehit_backend_postgres_data:/data -v ehit_backend_redis_data:/redis -v ${BACKUP_DIR}/${TIMESTAMP}:/backup alpine tar -czf /backup/volumes.tar.gz /data /redis
            ;;
        esac
        
        # Create backup info file
        cat > ${BACKUP_DIR}/${TIMESTAMP}/backup_info.txt << EOL
        Backup Type: ${BACKUP_TYPE}
        Timestamp: ${TIMESTAMP}
        Date: $(date)
        Server: $(hostname)
        Docker Containers:
        $(docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}")
        EOL
        
        # Compress entire backup
        echo "📦 Compressing backup..."
        cd ${BACKUP_DIR}
        tar -czf ${TIMESTAMP}_${BACKUP_TYPE}.tar.gz ${TIMESTAMP}/
        
        # Remove uncompressed directory
        rm -rf ${TIMESTAMP}/
        
        # Calculate backup size
        BACKUP_SIZE=$(du -h ${TIMESTAMP}_${BACKUP_TYPE}.tar.gz | cut -f1)
        
        echo "✅ Backup completed successfully!"
        echo "📊 Backup size: ${BACKUP_SIZE}"
        echo "📁 Location: ${BACKUP_DIR}/${TIMESTAMP}_${BACKUP_TYPE}.tar.gz"
        
        # Cleanup old backups
        echo "🧹 Cleaning up old backups..."
        find ${BACKUP_DIR} -name "*.tar.gz" -type f -mtime +${BACKUP_RETENTION_DAYS} -delete
        
        # List remaining backups
        echo "📋 Remaining backups:"
        ls -lh ${BACKUP_DIR}/*.tar.gz 2>/dev/null || echo "No backups found"
        
        EOF
        
        chmod +x backup.sh

    - name: 💾 Execute backup
      run: |
        ssh -o StrictHostKeyChecking=no root@165.227.180.118 'cd /opt/ehit_backend && chmod +x backup.sh && ./backup.sh'

    - name: 📤 Upload backup to GitHub (if small enough)
      run: |
        echo "📤 Checking if backup can be uploaded to GitHub..."
        # Note: GitHub has a 500MB limit for artifacts
        # For larger backups, consider using cloud storage services

    - name: 📊 Backup summary
      run: |
        echo "## 💾 Backup Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Type:** ${{ github.event.inputs.backup_type || 'full' }}" >> $GITHUB_STEP_SUMMARY
        echo "**Status:** ✅ Completed successfully" >> $GITHUB_STEP_SUMMARY
        echo "**Server:** 165.227.180.118" >> $GITHUB_STEP_SUMMARY
        echo "**Retention:** ${{ env.BACKUP_RETENTION_DAYS }} days" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Backup includes:**" >> $GITHUB_STEP_SUMMARY
        if [ "${{ github.event.inputs.backup_type || 'full' }}" == "full" ]; then
          echo "- ✅ Database dump" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Media files" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Static files" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Configuration files" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Docker volumes" >> $GITHUB_STEP_SUMMARY
        elif [ "${{ github.event.inputs.backup_type }}" == "database" ]; then
          echo "- ✅ Database dump only" >> $GITHUB_STEP_SUMMARY
        elif [ "${{ github.event.inputs.backup_type }}" == "media" ]; then
          echo "- ✅ Media files only" >> $GITHUB_STEP_SUMMARY
        elif [ "${{ github.event.inputs.backup_type }}" == "config" ]; then
          echo "- ✅ Configuration files only" >> $GITHUB_STEP_SUMMARY
        fi

  # Job de verificação de integridade do backup
  verify-backup:
    runs-on: ubuntu-latest
    needs: backup
    if: github.event.inputs.backup_type == 'full' || github.event.inputs.backup_type == ''

    steps:
    - name: 🔐 Setup SSH
      uses: webfactory/ssh-agent@v0.9.0
      with:
        ssh-private-key: ${{ secrets.SERVER_SSH_KEY }}

    - name: 🔍 Verify backup integrity
      run: |
        ssh -o StrictHostKeyChecking=no root@165.227.180.118 '
        echo "🔍 Verifying backup integrity..."
        
        BACKUP_DIR="/opt/backups"
        LATEST_BACKUP=$(ls -t ${BACKUP_DIR}/*.tar.gz | head -n1)
        
        if [ -f "${LATEST_BACKUP}" ]; then
          echo "📁 Latest backup: ${LATEST_BACKUP}"
          
          # Check if backup is not corrupted
          if tar -tzf "${LATEST_BACKUP}" > /dev/null 2>&1; then
            echo "✅ Backup integrity check passed"
            
            # Show backup contents
            echo "📋 Backup contents:"
            tar -tzf "${LATEST_BACKUP}" | head -20
            
            # Show backup size
            BACKUP_SIZE=$(du -h "${LATEST_BACKUP}" | cut -f1)
            echo "📊 Backup size: ${BACKUP_SIZE}"
            
          else
            echo "❌ Backup integrity check failed"
            exit 1
          fi
        else
          echo "❌ No backup found"
          exit 1
        fi
        '

    - name: 📊 Verification summary
      run: |
        echo "## 🔍 Backup Verification" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Status:** ✅ Backup integrity verified" >> $GITHUB_STEP_SUMMARY
        echo "**Verification:** All files accessible and not corrupted" >> $GITHUB_STEP_SUMMARY
